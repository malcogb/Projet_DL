# Projet_DL : D√©tection Automatique de Sentiment dans des Appels Vocaux √† l‚Äôaide de Wav2Vec 2.0 et BERT

# üéôÔ∏è Analyse de Sentiment Vocal avec Transcription Automatique

Ce projet utilise deux mod√®les puissants :
- **Wav2Vec2** pour la transcription vocale en texte (speech-to-text)
- **RoBERTa** pour l‚Äôanalyse de sentiment √† partir du texte transcrit

> **Objectif :** Permettre √† un utilisateur d'uploader un fichier audio `.wav` pour obtenir automatiquement :
> - sa transcription
> - l'analyse de sentiment
> - l'export des r√©sultats en JSON et CSV

---

## Fonctionnalit√©s

- **Transcription automatique** d'audio `.wav` (mod√®le : `jonatasgrosman/wav2vec2-large-xlsr-53-french`lien : )
- **Analyse de sentiment** (mod√®le : `cardiffnlp/twitter-xlm-roberta-base-sentiment` lien : )
- **Export des r√©sultats** en :
  - `results.json` (historique des pr√©dictions)
  - `results.csv` (version tabulaire exploitable)
- **Interface web** simple avec **Gradio** pour tester notre solution sur **colab**
- Nous cr√©√© aussi une **API** avec le FrameWork **FastAPI** dans **VSCode**

---

## Les √©tapes de r√©alisation du projet :

### 1. **Cr√©ation (`python -m venv venv`) et activation (`wandb_env\Scripts\activate`) d'un environnement virtuel** 

### 2. **Cr√©ation du repo GitHub** 
Nous cr√©√© ce repo `https://github.com/malcogb/Projet_DL.git`

### 3. Clonage du repo
Nous avons clon√© le repo pour l'avoir en local avce la commande : `git clone httpps://github.com/malcogb/Projet_DL.git`

### 4. **Installation des d√©pendances** 
Nous les avons directement install√©es dans une cellule sur Google Colab et avec `ip install -r requirements.txt` dans le terminal de VSCode

### 5. D√©veloppement de la solution "D√©tection Automatique de Sentiment dans les audios"
Apr√®s avoir fini le d√©loppement et test avec **Gradio** sur Colab, nous avons cr√©√© son API afin de rendre notre solution utilisable par d'autres d√©veloppeurs.

### 6. Utilisation
- Sur Colab : Nous lan√ßons l‚Äôinterface Gradio avec `demo.launch(share=True)` en fin de NoteBook Colab. accessible sur URL: `https://f9556ddf0a8961a72b.gradio.live`
- Dans VSCode, notre API (FastAPI) a √©t√© d√©velopp√©e en Python et nomm√©e `app.py`. Nous lan√ßons l'API avec la commande `uvicorn app:app --reload`. Une fois que le serveur **FastAPI** de notre **API** a d√©marr√©, nous nous connectons √† l'interface web (`http://127.0.0.1:8000`) ou directement sur `http://127.0.0.1:8000/docs`.

### 7. Endpoints de l'API
Nous avons utilis√© 3 endpoints √† savoir :
- **@app.post("/audio_transcription and sentiment_analyze/")** pour permettre √† l'utilisateur d'envoyer √† l'API le fichier audio
- **@app.get("/download_json/")** pour permettre √† l'utilisateur de t√©l√©charger le r√©sultat du traitement et de la pr√©diction en fichier JSON
- **@app.get("/download_csv/")** pour permettre √† l'utilisateur de t√©l√©charger le r√©sultat du traitement et de la pr√©diction en fichier CSV

### 8. Exemple de sortie apr√®s traitement du fichier audio
voir dossier capture

### 9. Export
**Apr√®s chaque analyse :**
- les r√©sultats sont ajout√©s dans results.json
- puis convertis automatiquement en results.csv

**10. Contenu des fichiers JSON et CSV :**
- Transcription
- Sentiment
- Confiance
- Nombre de chunks
- Score moyen
- Date (horodatage)
- Nom du fichier audio

### 11. √Ä faire / am√©liorations possibles
- Authentification des utilisateurs
- Support multilingue √©tendu
- Interface front-end pour visualiser les r√©sultats
- D√©ploiement sur HuggingFace Spaces ou Docker

### 12. Auteur
Projet d√©velopp√© par **Malco GBAKPA** √©tudiant en **Master 2 IA** Sp√©cialit√© **Data Science**
